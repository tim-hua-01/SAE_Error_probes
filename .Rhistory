for(i in 1:length(df$a)){
data = paste0(data,'[',as.character(df[[i,1]]), ',',as.character(df[[i,2]]),'],')
target  = paste0(target,'[',as.character(df[[i,3]]),'], ')
}
print(data)
print(target)
nand_approx <- function(a,b){
-1.1040*min(max(0.7866*a + 0.9095*b-0.6202,0),1) + 1.0553
}
nand_approx(1,1)
nand_approx(1,0)
nand_approx(0,1)
nand_approx(0,0)
nand_approx(1.2,1.2)
nand_approx(1.2,0.3)
nand_approx(1.1,0.3)
nand_approx <- function(a,b){
-1*min(max(5/6*a + 5/6*b-2/3,0),1) + 1
}
nand_approx(1,1)
nand_approx(1,0)
nand_approx(0,1)
nand_approx(0,0)
nand_approx(1.2,1.2)
nand_approx(1.1,0.3)
nand_approx(0,1)
nand_approx(0,0)
nand_approx(1.2,1.1)
nand_approx(1.1,0.1)
nand_approx(1.3,1.1)
nand_approx(1.3,0.1)
nand_approx <- function(a,b){
-1*min(max(5.5/6*a + 5/6*b-2/3,0),1) + 1
}
nand_approx(1,1)
nand_approx(1,0)
nand_approx(0,1)
nand_approx(0,0)
nand_approx(1.3,1.1)
nand_approx(1.3,0.1)
nand_approx(0,1)
nand_approx(0,0)
nand_approx(1,0.1)
nand_approx <- function(a,b){
min(max(-a - b + 1,0),1) #+ 1
}
nand_approx(1,1)
nand_approx(1,0)
nand_approx(0,1)
nand_approx(0,0)
1.75+1.5+1+0.5
log2(17184)
library(readr)
random <- read_csv("~/Desktop/random.csv")
View(random)
sum(random$Amount)
library(readr)
random <- read_csv("~/Desktop/random.csv")
View(random)
sum(random$Amount)
563.06 0 336.55
563.06 - 336.55
226.51-38.00-8.15
A = rbind(c(1,2), c(5,6))
solve(A, c(3,7))
rref(rbind(c(1,2,3,4), c(5,6,7,8)))
install.packages('pracma')
pracma::rref(rbind(c(1,2,3,4), c(5,6,7,8)))
sample(1:16000, 1)
library(readr)
feature_layer_19 <- read_csv("~/Desktop/feature_layer_19.csv")
View(feature_layer_19)
library(tidyverse)
w_0 <- feature_layer_19 %>% filter(agg_actv*no_agg_actv == 0)
View(w_0)
mean(feature_layer_19$agg_actv)
mean(feature_layer_19$no_agg_actv)
library(tidyverse)
df <- tibble(
item = c('monitor1', 'monitor2', 'away suitcase', 'chair', 'box1', 'mikalya supplies'),
dollars = c(50, 130, 130, 200, 93, 70)
)
sum*df$dollars
sum(df$dollars()
sum(df$dollars)
130+130+93
130+130+93+80 + 45
library(tidyverse)
df <- read_csv("~/Downloads/[Do not share with non-attendees] EAGxBerkeley 2024 – Swapcard Attendee Data - Attendee Data.csv")
View(df)
df <- read_csv("~/Downloads/[Do not share with non-attendees] EAGxBerkeley 2024 – Swapcard Attendee Data - Attendee Data.csv")
df <- read_csv("~/Downloads/[Do not share with non-attendees] EAGxBerkeley 2024 – Swapcard Attendee Data - Attendee Data.csv")
animal <-df %>% filter(str_detect(Biography, 'animal') , !str_detect(Biography,'(ai)|(AI)'))
View(animal)
animal <-df %>% filter(!str_detect(Biography, 'animal')| str_detect(Biography,'(ai)|(AI)'))
animal <-df %>% filter(!str_detect(Biography, 'animal')|str_detect(Biography,'(ai)|(AI)'))
animal <-df %>% filter(!str_detect(Biography, 'animal'))
animal <-df %>% filter(str_detect(Biography, 'animal'))
animal <-df %>% filter(str_detect(Biography, 'animal'), str_detect(`How I Can Help Others`, 'animal'))
animal <-df %>% filter(ifelse(is.na(Biography), TRUE, str_detect(Biography, 'animal')), str_detect(`How I Can Help Others`, 'animal'))
animal <-df %>% filter(ifelse(is.na(Biography), TRUE, str_detect(Biography, 'animal')), ifelse(is.na(`How I Can Help Others`), TRUE,str_detect(`How I Can Help Others`, 'animal')))
animal <-df %>% filter(ifelse(is.na(Biography), TRUE, str_detect(Biography, 'animal')), ifelse(is.na(`How I Can Help Others`), TRUE,str_detect(`How I Can Help Others`, 'animal'))) %>% filter(is.na(Biography) | is.na(`How I Can Help Others`))
animal <-df %>% filter(ifelse(is.na(Biography), TRUE, str_detect(Biography, 'animal')), ifelse(is.na(`How I Can Help Others`), TRUE,str_detect(`How I Can Help Others`, 'animal'))) %>% filter(!is.na(Biography) | !is.na(`How I Can Help Others`))
df %>% anti_join(animal)
library(magrittr)
df %<>% anti_join(animal)
df %>% filter(is.na(Biography), is.na(`How I Can Help Others`))
df %<>% filter(is.na(Biography), is.na(`How I Can Help Others`))
df
write_csv(df,'conference.csv')
df <- read_csv("~/Downloads/[Do not share with non-attendees] EAGxBerkeley 2024 – Swapcard Attendee Data - Attendee Data.csv")
animal <-df %>% filter(ifelse(is.na(Biography), TRUE, str_detect(Biography, 'animal')), ifelse(is.na(`How I Can Help Others`), TRUE,str_detect(`How I Can Help Others`, 'animal'))) %>% filter(!is.na(Biography) | !is.na(`How I Can Help Others`))
df %<>% anti_join(animal)
df %>% filter(!is.na(Biography), !is.na(`How I Can Help Others`))
filt <- df %>% filter(!is.na(Biography), !is.na(`How I Can Help Others`))
filt <- df %>% filter(!is.na(Biography) | !is.na(`How I Can Help Others`))
filt
View(filt)
write_csv(filt,'conference.csv')
write_csv(filt %>% select(`First Name`, `Last Name`, Company, `Job Title`, Biography,`How Others Can Help Me`, `How I Can Help Others`),'conference.csv')
0.8*1.12*(66*2+90+75*11)
147.84+100.80+756.00
1004.64-938.112
66.528-18
library(readr)
obfuscations <- read_csv("~/OneDrive/Coding/Github clones/concept_universality/data/google_gemma-2-9b/obfuscations.csv")
View(obfuscations)
View(obfuscations)
setwd("~/Downloads")
library(tidyverse)
library(stringi)
library(magrittr)
gemma_res <- read_csv("generated_response_half.csv")
View(gemma_res)
gemma_res %>% arrange(prompt_template, concept, obfuscation_name)
gemma_res %<>% arrange(prompt_template, concept, obfuscation_name)
write_csv(gemma_res, 'gemma_9b_res.csv')
library(readr)
llama_generated_response_half <- read_csv("llama_generated_response_half.csv")
View(llama_generated_response_half)
llama_generated_response_half %<>% arrange(prompt_template, concept, obfuscation_name)
write_csv(llama_generated_response_half, 'llama_3.1_8b_res.csv')
llama_generated_response_half %>% filter(obfuscation_name == 'char_dropout')
a <- llama_generated_response_half %>% filter(obfuscation_name == 'char_dropout')
View(a)
succ_gemma <- gemma_res %>% filter(toxic == 1)
succ_gemma <- gemma_res %>% filter(toxic == 1, str_detect(greedy_generation, 'I cannot', TRUE))
View(succ_gemma)
succ_gemma <- gemma_res %>% filter(toxic == 1, str_detect(greedy_generation, '(I cannot|I can't), TRUE))
succ_gemma <- gemma_res %>% filter(toxic == 1, str_detect(greedy_generation, "(I cannot|I can't)", TRUE))
succ_llama <- llama_generated_response_half %>% filter(toxic == 1, str_detect(greedy_generation, "(I cannot|I can't)", TRUE))
View(succ_llama)
a <- llama_generated_response_half %>% filter(prompt = 'How to make a POisOn')
a <- llama_generated_response_half %>% filter(prompt == 'How to make a POisOn')
a$greedy_generation
str_detext(a$greedy_generation, "I can't")
str_detect(a$greedy_generation, "I can't")
str_detect(a$greedy_generation, "I can’t")
harmb <-read_csv("harmbench_behaviors_text_all.csv")
View(harmb)
harmb %>% filter(FunctionalCategory == 'standard') %>% count(SemanticCategory)
harmb %>% filter(FunctionalCategory == 'standard') %>% View()
gemma_res %>% filter(toxic == 1)
gemma_res %>% filter(toxic == 1) %>% filter(str_)
gemma_res %>% filter(toxic == 1) %>% filter(str_detect(greedy_generation, 'It sounds like'))
gemma_res %>% filter(str_detect(greedy_generation, 'It sounds like'))
harml8b <- read_csv("benchmark-advbench-50.decorated.evaluated_Meta-Llama-3-8B-Instruct.csv")
View(harml8b)
harml8b %>% count(harmful_prompt_source)
View(harml8b)
harml8b %>% count(eval_harmful)
badbot <- harml8b %>% filter(eval_harmful == 'BAD BOT')
View(badbot)
write_csv(badbot, 'temp.csv')
setwd("~/Downloads")
write_csv(badbot, 'temp.csv')
0.64-1.96*0.485/sqrt(50)
0.64-1.63*0.485/sqrt(50)
#temp
library(tidyverse)
library(magrittr)
df <- read_csv('results.csv')
View(df)
library(skimr)
skim(df)
df %>% group_by(n/m) %>% summarise(mean(my_loss - trained_loss))
df %>% group_by(n/m) %>% summarise(mean(my_loss/trained_loss))
df %>% group_by(k) %>% summarise(mean(my_loss/trained_loss))
df <- read_csv('results.csv')
df %<>% mutate(delta = my_loss - trained_loss, prop = my_loss/trained_loss)
skim(df)
skim(df)
quantile(df$prop, c(0,0.03,0.05,0.1,0.9,0.95,0.97,1))
library(tidyverse)
library(magrittr)
df <- read_csv('fin_stuff_to_look_at.csv')
library(skimr)
#df %<>% mutate(delta = my_loss - trained_loss, prop = my_loss/trained_loss)
skim(df)
sort(colnames(df))
df["You prefer it when the mentally altered person is: (u6xfdy0)"]
!is.na(df["You prefer it when the mentally altered person is: (u6xfdy0)"])
#df %<>% mutate(delta = my_loss - trained_loss, prop = my_loss/trained_loss)
skim(df)
sort(colnames(df))
a <- !is.na(df["You prefer it when the mentally altered person is: (u6xfdy0)"]) and TRUE
a <- !is.na(df["You prefer it when the mentally altered person is: (u6xfdy0)"]) & TRUE
a <- !is.na(df[["You prefer it when the mentally altered person is: (u6xfdy0)"]]) & TRUE
a <- !is.na(df[["You prefer it when the mentally altered person is: (u6xfdy0)"]]) & !is.na(df[["You prefer it when the mentally altered person is: (vthtd49)"]])
sum(a)
a <- !is.na(df[["You prefer it when the mentally altered person is: (u6xfdy0)"]]) & is.na(df[["You prefer it when the mentally altered person is: (vthtd49)"]])
sum(a)
a <- !is.na(df[["You find vore in which orifices to be erotic? (hv84q73)"]]) & !is.na(df[["You find vore in which orifices to be erotic? (bdjwhl)"]])
sum(a)
a <- !is.na(df[["Which of the following types of mental alteration do you find erotic? (khwsw7b)"]]) & !is.na(df[["Which of the following types of mental alteration do you find erotic? (1kbu0vr)"]])
sum(a)
setwd("~/OneDrive/Coding/AISC/SAE_Error_probes")
basketball <- read_csv('probe_results_ath_sport.csv')
#Probing data analysis clean
setwd("~/Library/CloudStorage/OneDrive-Personal/Coding/AISC/SAE_Error_probes")
if (!require(tidyverse)) install.packages("tidyverse"); library(tidyverse)
if (!require(magrittr)) install.packages("magrittr"); library(magrittr)
library(estimatr)
library(skimr)
library(modelsummary)
library(fixest)
myTheme <- theme(plot.title = element_text(size = 14),
panel.background = element_rect(fill = '#F2F2ED'),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10, colour = 'black'),
legend.title = element_text(size = 12),
legend.position = "right",
legend.background = element_rect(linetype = 3,size = 0.5, color = 'black', fill = 'grey94'),
legend.text = element_text(size = 10),
legend.key = element_rect(size = 0.5, linetype = 1, color = 'black'))
#I also have some nice colors that I use in my various graphs.
nicepurp <- "#A88DBF"
niceblue <- '#38A5E0'
nicegreen <- '#A3DCC0'
custom_colors <- c("#2ECC71", "#A3E635", "#F4D03F", "#F39C12", "#E74C3C", "#C0392B")
#Functions
#####
probe_summarizer <- function(probe_name, some_probes){
# Renaming the columns to replace spaces with underscores
colnames(some_probes) <- gsub(" ", "_", colnames(some_probes))
# Modified probe_summary code
probe_summary <- some_probes %>% group_by(`Feature_Type`) %>%
summarize(mean_test_accuracy = mean(`Test_Accuracy`),
se_test_accuracy = sd(`Test_Accuracy`)/sqrt(n()),
mean_test_loss = mean(`Test_Loss`),
se_test_loss = sd(`Test_Loss`)/sqrt(n())) %>% ungroup()
probe_summary %<>% mutate(graph_labels = c(
"SAE Error",
"Residual",
"SAE Reconstruction"))
ggplot(probe_summary, aes(x = graph_labels,
y = mean_test_accuracy,)) +
geom_point() + myTheme +
labs(y = 'Probe Out of Sample Accuracy', x = NULL,
title = str_c(probe_name, " Out of Sample Accuracy"),
subtitle = "Error bars indicate randomness from using different seeds") +
geom_errorbar(aes(ymin = mean_test_accuracy - 1.96*se_test_accuracy,
ymax = mean_test_accuracy + 1.96*se_test_accuracy),
width = 0.1)+
scale_y_continuous(labels = scales::percent)
ggsave(str_c("R plots/", probe_name, "_oos_accuracy.png"), width = 6, height = 4, scale = 1.2)
ggplot(probe_summary, aes(x = graph_labels,
y = mean_test_loss,)) +
geom_point() + myTheme +
labs(y = 'Probe Out of Sample Loss', x = NULL,
title = str_c(probe_name, " Out of Sample Loss"),
subtitle = "Error bars indicate randomness from using different seeds") +
geom_errorbar(aes(ymin = mean_test_loss - 1.96*se_test_loss,
ymax = mean_test_loss + 1.96*se_test_loss),
width = 0.1)+
scale_y_continuous()
ggsave(str_c("R plots/", probe_name, "_oos_loss.png"), width = 6, height = 4, scale = 1.2)
print(modelsummary(feols(Test_Loss ~ Feature_Type | as.factor(Seed), data = some_probes, vcov = ~Seed),
fmt = "%.3f",        # 3 decimal places
stars = TRUE,title = "Test loss mean differences",            # Show confidence intervals instead of std errors
statistic = c("conf.int"),
conf_level = 0.95,
coef_map = c(
"Feature_Typesae_input" = "Residual - SAE Error",
"Feature_Typesae_recons" = "SAE Reconstruction - SAE Error"
),
gof_map = list(
list(raw = "nobs", clean = "Num.Obs.", fmt = 0),
list(raw = "r.squared", clean = "R²", fmt = "%.3f"),
list(raw = "std.error", clean = "Std.Errors", fmt = "%.3f")
),# Add significance stars
output = "markdown"))
print(modelsummary(feols(Test_Accuracy ~ Feature_Type | as.factor(Seed), data = some_probes, vcov = ~Seed),
fmt = "%.3f",        # 3 decimal places
stars = TRUE,title = "Test accuracy mean differences",            # Show confidence intervals instead of std errors
statistic = c("conf.int"),
conf_level = 0.95,
coef_map = c(
"Feature_Typesae_input" = "Residual - SAE Error",
"Feature_Typesae_recons" = "SAE Reconstruction - SAE Error"
),
gof_map = list(
list(raw = "nobs", clean = "Num.Obs.", fmt = 0),
list(raw = "r.squared", clean = "R²", fmt = "%.3f"),
list(raw = "std.error", clean = "Std.Errors", fmt = "%.3f")
),# Add significance stars
output = "markdown"))
}
#####
#Truth probe
#Data summari
truth_probes <- read_csv('probe_results_truth.csv')
probe_summarizer('Probing for Truth in Cities Dataset', truth_probes)
#Probing data analysis clean
setwd("~/Library/CloudStorage/OneDrive-Personal/Coding/AISC/SAE_Error_probes")
if (!require(tidyverse)) install.packages("tidyverse"); library(tidyverse)
if (!require(magrittr)) install.packages("magrittr"); library(magrittr)
library(estimatr)
library(skimr)
library(modelsummary)
library(fixest)
myTheme <- theme(plot.title = element_text(size = 14),
panel.background = element_rect(fill = '#F2F2ED'),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10, colour = 'black'),
legend.title = element_text(size = 12),
legend.position = "right",
legend.background = element_rect(linetype = 3,size = 0.5, color = 'black', fill = 'grey94'),
legend.text = element_text(size = 10),
legend.key = element_rect(size = 0.5, linetype = 1, color = 'black'))
#I also have some nice colors that I use in my various graphs.
nicepurp <- "#A88DBF"
niceblue <- '#38A5E0'
nicegreen <- '#A3DCC0'
custom_colors <- c("#2ECC71", "#A3E635", "#F4D03F", "#F39C12", "#E74C3C", "#C0392B")
#Functions
#####
probe_summarizer <- function(probe_name, some_probes){
# Renaming the columns to replace spaces with underscores
colnames(some_probes) <- gsub(" ", "_", colnames(some_probes))
# Modified probe_summary code
probe_summary <- some_probes %>% group_by(`Feature_Type`) %>%
summarize(mean_test_accuracy = mean(`Test_Accuracy`),
se_test_accuracy = sd(`Test_Accuracy`)/sqrt(n()),
mean_test_loss = mean(`Test_Loss`),
se_test_loss = sd(`Test_Loss`)/sqrt(n())) %>% ungroup()
probe_summary %<>% mutate(graph_labels = c(
"SAE Error",
"Residual",
"SAE Reconstruction"))
ggplot(probe_summary, aes(x = graph_labels,
y = mean_test_accuracy,)) +
geom_point() + myTheme +
labs(y = 'Probe Out of Sample Accuracy', x = NULL,
title = str_c(probe_name, " Out of Sample Accuracy"),
subtitle = "Error bars indicate randomness from using different seeds",
caption = "Layer 21 with layer_21/width_16k/average_l0_139") +
geom_errorbar(aes(ymin = mean_test_accuracy - 1.96*se_test_accuracy,
ymax = mean_test_accuracy + 1.96*se_test_accuracy),
width = 0.1)+
scale_y_continuous(labels = scales::percent)
ggsave(str_c("R plots/", probe_name, "_oos_accuracy.png"), width = 6, height = 4, scale = 1.2)
ggplot(probe_summary, aes(x = graph_labels,
y = mean_test_loss,)) +
geom_point() + myTheme +
labs(y = 'Probe Out of Sample Loss', x = NULL,
title = str_c(probe_name, " Out of Sample Loss"),
subtitle = "Error bars indicate randomness from using different seeds",
caption = "Layer 21 with layer_21/width_16k/average_l0_139") +
geom_errorbar(aes(ymin = mean_test_loss - 1.96*se_test_loss,
ymax = mean_test_loss + 1.96*se_test_loss),
width = 0.1)+
scale_y_continuous()
ggsave(str_c("R plots/", probe_name, "_oos_loss.png"), width = 6, height = 4, scale = 1.2)
print(modelsummary(feols(Test_Loss ~ Feature_Type | as.factor(Seed), data = some_probes, vcov = ~Seed),
fmt = "%.3f",        # 3 decimal places
stars = TRUE,title = "Test loss mean differences Layer 21",            # Show confidence intervals instead of std errors
statistic = c("conf.int"),
conf_level = 0.95,
coef_map = c(
"Feature_Typesae_input" = "Residual - SAE Error",
"Feature_Typesae_recons" = "SAE Reconstruction - SAE Error"
),
gof_map = list(
list(raw = "nobs", clean = "Num.Obs.", fmt = 0),
list(raw = "r.squared", clean = "R²", fmt = "%.3f"),
list(raw = "std.error", clean = "Std.Errors", fmt = "%.3f")
),# Add significance stars
output = "markdown"))
print(modelsummary(feols(Test_Accuracy ~ Feature_Type | as.factor(Seed), data = some_probes, vcov = ~Seed),
fmt = "%.3f",        # 3 decimal places
stars = TRUE,title = "Test accuracy mean differences Layer 21",            # Show confidence intervals instead of std errors
statistic = c("conf.int"),
conf_level = 0.95,
coef_map = c(
"Feature_Typesae_input" = "Residual - SAE Error",
"Feature_Typesae_recons" = "SAE Reconstruction - SAE Error"
),
gof_map = list(
list(raw = "nobs", clean = "Num.Obs.", fmt = 0),
list(raw = "r.squared", clean = "R²", fmt = "%.3f"),
list(raw = "std.error", clean = "Std.Errors", fmt = "%.3f")
),# Add significance stars
output = "markdown"))
}
#####
#Truth probe
#Data summari
truth_probes <- read_csv('probe_results_truth.csv')
probe_summarizer('Probing for Truth in Cities Dataset', truth_probes)
truth_probes_2nd <- read_csv('probe_results_truth_second_last.csv')
probe_summarizer('Probing for Truth (2nd last token)', truth_probes_2nd)
headline_probes <- read_csv('probe_results_hl_frontp.csv')
probe_summarizer('Probing for Front Page Headlines', headline_probes)
truth_probes <- read_csv('probe_results_truth.csv')
probe_summarizer('Probing for Truth in Cities Dataset', truth_probes)
truth_probes_2nd <- read_csv('probe_results_truth_second_last.csv')
probe_summarizer('Probing for Truth (2nd last token)', truth_probes_2nd)
probe_summarizer <- function(probe_name, some_probes){
# Renaming the columns to replace spaces with underscores
colnames(some_probes) <- gsub(" ", "_", colnames(some_probes))
# Modified probe_summary code
probe_summary <- some_probes %>% group_by(`Feature_Type`) %>%
summarize(mean_test_accuracy = mean(`Test_Accuracy`),
se_test_accuracy = sd(`Test_Accuracy`)/sqrt(n()),
mean_test_loss = mean(`Test_Loss`),
se_test_loss = sd(`Test_Loss`)/sqrt(n())) %>% ungroup()
probe_summary %<>% mutate(graph_labels = c(
"SAE Error",
"Residual",
"SAE Reconstruction"))
ggplot(probe_summary, aes(x = graph_labels,
y = mean_test_accuracy,)) +
geom_point() + myTheme +
labs(y = 'Probe Out of Sample Accuracy', x = NULL,
title = str_c(probe_name, " Out of Sample Accuracy"),
subtitle = "Error bars indicate randomness from using different seeds",
caption = "Layer 21 with layer_21/width_16k/average_l0_139") +
geom_errorbar(aes(ymin = mean_test_accuracy - 1.96*se_test_accuracy,
ymax = mean_test_accuracy + 1.96*se_test_accuracy),
width = 0.1)+
scale_y_continuous(labels = scales::percent)
ggsave(str_c("R plots/", probe_name, "_oos_accuracy.png"), width = 6, height = 4, scale = 1.2)
ggplot(probe_summary, aes(x = graph_labels,
y = mean_test_loss,)) +
geom_point() + myTheme +
labs(y = 'Probe Out of Sample Loss', x = NULL,
title = str_c(probe_name, " Out of Sample Loss"),
subtitle = "Error bars indicate randomness from using different seeds",
caption = "Layer 21 with layer_21/width_16k/average_l0_139") +
geom_errorbar(aes(ymin = mean_test_loss - 1.96*se_test_loss,
ymax = mean_test_loss + 1.96*se_test_loss),
width = 0.1)+
scale_y_continuous()
ggsave(str_c("R plots/", probe_name, "_oos_loss.png"), width = 6, height = 4, scale = 1.2)
print(modelsummary(feols(Test_Loss ~ Feature_Type | as.factor(Seed), data = some_probes, vcov = ~Seed),
fmt = "%.3f",        # 3 decimal places
stars = TRUE,title = str_c(probe_name,": Test loss mean differences Layer 21"),            # Show confidence intervals instead of std errors
statistic = c("conf.int"),
conf_level = 0.95,
coef_map = c(
"Feature_Typesae_input" = "Residual - SAE Error",
"Feature_Typesae_recons" = "SAE Reconstruction - SAE Error"
),
gof_map = list(
list(raw = "nobs", clean = "Num.Obs.", fmt = 0),
list(raw = "r.squared", clean = "R²", fmt = "%.3f"),
list(raw = "std.error", clean = "Std.Errors", fmt = "%.3f")
),# Add significance stars
output = "markdown"))
print(modelsummary(feols(Test_Accuracy ~ Feature_Type | as.factor(Seed), data = some_probes, vcov = ~Seed),
fmt = "%.3f",        # 3 decimal places
stars = TRUE,title = str_c(probe_name,": Test accuracy mean differences Layer 21"),            # Show confidence intervals instead of std errors
statistic = c("conf.int"),
conf_level = 0.95,
coef_map = c(
"Feature_Typesae_input" = "Residual - SAE Error",
"Feature_Typesae_recons" = "SAE Reconstruction - SAE Error"
),
gof_map = list(
list(raw = "nobs", clean = "Num.Obs.", fmt = 0),
list(raw = "r.squared", clean = "R²", fmt = "%.3f"),
list(raw = "std.error", clean = "Std.Errors", fmt = "%.3f")
),# Add significance stars
output = "markdown"))
}
probe_summarizer('Probing for Truth in Cities Dataset', truth_probes)
probe_summarizer('Probing for Truth (2nd last token)', truth_probes_2nd)
headline_probes <- read_csv('probe_results_hl_frontp.csv')
probe_summarizer('Probing for Front Page Headlines', headline_probes)
manhattan_probes <- read_csv('probe_results_man_borough.csv')
probe_summarizer('Probing for in Manhattan', manhattan_probes)
tw_happy <- read_csv('probe_results_tw_happiness.csv')
probe_summarizer('Probing for Happiness in Tweets', tw_happy)
basketball <- read_csv('probe_results_ath_sport.csv')
probe_summarizer('Probing for Basketball Atheletes', basketball)
twoshot <- read_csv('probe_results_twoshot.csv')
probe_summarizer('Probing for Basketball Atheletes', twoshot)
probe_summarizer('Probing for Truth with Two shot prompt', twoshot)
steering_results_truth <- read_csv("~/OneDrive/Coding/AISC/SAE_Error_probes/steering_results_truth.csv")
View(steering_results_truth)
steering_results_truth <- read_csv("~/OneDrive/Coding/AISC/SAE_Error_probes/steering_results_truth.csv")
feols(Steered_Logit_Diff ~ as.factor(Scaling_Factor) | Sample_Index,
data = steering_results_truth %>% filter(Feature_Type == "sae_input"), vcov = ~Sample_Index)
feols(Steered_Logit_Diff ~ as.factor(Scaling_Factor) | Sample_Index,
data = steering_results_truth %>% filter(Feature_Type == "sae_recons"), vcov = ~Sample_Index)
feols(Steered_Logit_Diff ~ as.factor(Scaling_Factor) | Sample_Index,
data = steering_results_truth %>% filter(Feature_Type == "sae_diff"), vcov = ~Sample_Index)
mean(steering_results_truth$Baseline_LogProb_Token1 - steering_results_truth$Baseline_LogProb_Token2)
mean(abs(steering_results_truth$Baseline_LogProb_Token1 - steering_results_truth$Baseline_LogProb_Token2))
abs(steering_results_truth$Baseline_LogProb_Token1 - steering_results_truth$Baseline_LogProb_Token2)
mean(abs(steering_results_truth$Baseline_LogProb_Token1 - steering_results_truth$Baseline_LogProb_Token2))
